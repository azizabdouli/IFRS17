# ml/data_preprocessing.py

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler
from sklearn.impute import SimpleImputer
from typing import Tuple, Dict, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class DataPreprocessor:
    """
    Classe pour le pr√©processing des donn√©es IFRS17 PAA
    """
    
    def __init__(self):
        self.scalers = {}
        self.encoders = {}
        self.imputers = {}
        
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Nettoyage initial des donn√©es
        """
        df_clean = df.copy()
        
        # Conversion des colonnes num√©riques importantes
        numeric_columns = ['DUREE', 'MNTPRNET', 'MNTPPNA', 'MNTACCESS', 'MNTPRASSI', 
                          'NBPPNATOT', 'NBPPNAJ', 'NUMQUITT', 'CODFAM', 'CODPROD', 'FRACT']
        for col in numeric_columns:
            if col in df_clean.columns:
                df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')
        
        # Conversion des dates
        date_columns = ['DATECREA', 'DATEEMISS', 'DEBEFFQUI', 'FINEFFQUI', 'DATEPAIEM']
        for col in date_columns:
            if col in df_clean.columns:
                df_clean[col] = pd.to_datetime(df_clean[col], format='%Y%m%d', errors='coerce')
        
        # Cr√©ation de features temporelles
        if 'DEBEFFQUI' in df_clean.columns:
            df_clean['annee_effet'] = df_clean['DEBEFFQUI'].dt.year
            df_clean['mois_effet'] = df_clean['DEBEFFQUI'].dt.month
            df_clean['jour_semaine_effet'] = df_clean['DEBEFFQUI'].dt.dayofweek
            
        if 'DATEEMISS' in df_clean.columns:
            df_clean['annee_emission'] = df_clean['DATEEMISS'].dt.year
            df_clean['mois_emission'] = df_clean['DATEEMISS'].dt.month
            
        # Calcul de dur√©es
        if 'DEBEFFQUI' in df_clean.columns and 'FINEFFQUI' in df_clean.columns:
            df_clean['duree_contrat_jours'] = (df_clean['FINEFFQUI'] - df_clean['DEBEFFQUI']).dt.days
            df_clean['duree_contrat_annees'] = df_clean['duree_contrat_jours'] / 365.25
            
        # Ratios financiers
        if 'MNTPRNET' in df_clean.columns and 'MNTPRASSI' in df_clean.columns:
            df_clean['ratio_prime_assure'] = df_clean['MNTPRNET'] / (df_clean['MNTPRASSI'] + 1e-8)
            
        if 'MNTPPNA' in df_clean.columns and 'NBPPNATOT' in df_clean.columns:
            df_clean['ppna_par_unite'] = df_clean['MNTPPNA'] / (df_clean['NBPPNATOT'] + 1e-8)
            
        # Indicateurs de risque
        if 'DUREE' in df_clean.columns:
            # Convertir DUREE en num√©rique en g√©rant les erreurs
            df_clean['DUREE'] = pd.to_numeric(df_clean['DUREE'], errors='coerce')
            df_clean['contrat_long_terme'] = (df_clean['DUREE'] > 12).astype(int)
        else:
            df_clean['contrat_long_terme'] = 0
            
        if 'MNTPRNET' in df_clean.columns:
            df_clean['prime_elevee'] = (df_clean['MNTPRNET'] > df_clean['MNTPRNET'].quantile(0.75)).astype(int)
        else:
            df_clean['prime_elevee'] = 0
        
        return df_clean
    
    def encode_categorical_features(self, df: pd.DataFrame, categorical_columns: list = None) -> pd.DataFrame:
        """
        Encodage des variables cat√©gorielles
        """
        df_encoded = df.copy()
        
        if categorical_columns is None:
            categorical_columns = ['CODFAM', 'CODPROD', 'CODFORMU', 'TYPEEMMIS', 'STATQUIT', 'STADECTX', 'STATU']
            categorical_columns = [col for col in categorical_columns if col in df.columns]
        
        for col in categorical_columns:
            if col not in self.encoders:
                self.encoders[col] = LabelEncoder()
                df_encoded[col + '_encoded'] = self.encoders[col].fit_transform(df[col].astype(str))
            else:
                # Pour de nouvelles donn√©es
                try:
                    df_encoded[col + '_encoded'] = self.encoders[col].transform(df[col].astype(str))
                except ValueError:
                    # G√©rer les nouvelles cat√©gories
                    df_encoded[col + '_encoded'] = 0
                    
        return df_encoded
    
    def handle_missing_values(self, df: pd.DataFrame, strategy: str = 'median') -> pd.DataFrame:
        """
        Gestion des valeurs manquantes
        """
        df_imputed = df.copy()
        
        # Colonnes num√©riques
        numeric_columns = df.select_dtypes(include=[np.number]).columns
        
        for col in numeric_columns:
            # V√©rifier si la colonne a des valeurs non-NaN
            if df_imputed[col].notna().sum() == 0:
                logger.warning(f"‚ö†Ô∏è Colonne '{col}' enti√®rement NaN, remplacement par 0")
                df_imputed[col] = 0
                continue
                
            if col not in self.imputers:
                self.imputers[col] = SimpleImputer(strategy=strategy)
                try:
                    imputed_values = self.imputers[col].fit_transform(df_imputed[[col]])
                    df_imputed[col] = imputed_values.flatten()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Imputation √©chou√©e pour '{col}': {e}, utilisation de 0")
                    df_imputed[col] = df_imputed[col].fillna(0)
            else:
                try:
                    imputed_values = self.imputers[col].transform(df_imputed[[col]])
                    df_imputed[col] = imputed_values.flatten()
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Imputation √©chou√©e pour '{col}': {e}, utilisation de 0")
                    df_imputed[col] = df_imputed[col].fillna(0)
                
        return df_imputed
    
    def scale_features(self, df: pd.DataFrame, features_to_scale: list = None, scaler_type: str = 'standard') -> pd.DataFrame:
        """
        Normalisation des features
        """
        df_scaled = df.copy()
        
        if features_to_scale is None:
            features_to_scale = ['MNTPRNET', 'MNTACCESS', 'MNTPRASSI', 'NBPPNATOT', 'NBPPNAJ', 'MNTPPNA', 'DUREE']
            features_to_scale = [col for col in features_to_scale if col in df.columns]
        
        scaler_key = f"{scaler_type}_scaler"
        if scaler_key not in self.scalers:
            if scaler_type == 'standard':
                self.scalers[scaler_key] = StandardScaler()
            elif scaler_type == 'minmax':
                self.scalers[scaler_key] = MinMaxScaler()
                
            df_scaled[features_to_scale] = self.scalers[scaler_key].fit_transform(df[features_to_scale])
        else:
            df_scaled[features_to_scale] = self.scalers[scaler_key].transform(df[features_to_scale])
            
        return df_scaled
    
    def create_features_for_ml(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Cr√©ation de features sp√©cifiques pour le ML
        """
        df_features = df.copy()
        
        # Features d'agr√©gation par produit
        if 'CODPROD' in df.columns and 'MNTPRNET' in df.columns:
            prod_stats = df.groupby('CODPROD')['MNTPRNET'].agg(['mean', 'std', 'count']).reset_index()
            prod_stats.columns = ['CODPROD', 'avg_prime_produit', 'std_prime_produit', 'nb_contrats_produit']
            df_features = df_features.merge(prod_stats, on='CODPROD', how='left')
            
        # Features d'agr√©gation par famille
        if 'CODFAM' in df.columns and 'MNTPRNET' in df.columns:
            fam_stats = df.groupby('CODFAM')['MNTPRNET'].agg(['mean', 'median']).reset_index()
            fam_stats.columns = ['CODFAM', 'avg_prime_famille', 'median_prime_famille']
            df_features = df_features.merge(fam_stats, on='CODFAM', how='left')
            
        # Features temporelles avanc√©es
        if 'annee_effet' in df_features.columns:
            df_features['anciennete_produit'] = 2024 - df_features['annee_effet']
            
        # Features de saisonnalit√©
        if 'mois_effet' in df_features.columns:
            df_features['saison'] = df_features['mois_effet'].map({
                12: 'hiver', 1: 'hiver', 2: 'hiver',
                3: 'printemps', 4: 'printemps', 5: 'printemps',
                6: 'ete', 7: 'ete', 8: 'ete',
                9: 'automne', 10: 'automne', 11: 'automne'
            })
            
        return df_features
    
    def prepare_data_for_training(self, df: pd.DataFrame, target_column: str = None) -> Tuple[pd.DataFrame, pd.Series]:
        """
        Pr√©paration compl√®te des donn√©es pour l'entra√Ænement
        """
        logger.info("D√©but du preprocessing des donn√©es...")
        
        # 1. Nettoyage
        df_clean = self.clean_data(df)
        logger.info("‚úÖ Nettoyage termin√©")
        
        # 2. Cr√©ation de features
        df_features = self.create_features_for_ml(df_clean)
        logger.info("‚úÖ Cr√©ation de features termin√©e")
        
        # 3. Encodage cat√©goriel
        df_encoded = self.encode_categorical_features(df_features)
        logger.info("‚úÖ Encodage cat√©goriel termin√©")
        
        # 4. Gestion des valeurs manquantes
        df_imputed = self.handle_missing_values(df_encoded)
        logger.info("‚úÖ Gestion des valeurs manquantes termin√©e")
        
        # 5. Extraction du target AVANT la s√©lection des features
        y = None
        if target_column and target_column in df_imputed.columns:
            y = df_imputed[target_column].copy()
            df_imputed = df_imputed.drop(columns=[target_column])
            
            # Encodage du target cat√©goriel pour XGBoost
            if y.dtype == 'object' or isinstance(y.dtype, pd.CategoricalDtype):
                from sklearn.preprocessing import LabelEncoder
                label_encoder = LabelEncoder()
                y_encoded = label_encoder.fit_transform(y)
                y = pd.Series(y_encoded, index=y.index, name=y.name)
                logger.info(f"üè∑Ô∏è Target cat√©goriel encod√©: {label_encoder.classes_} -> {sorted(y.unique())}")
            
            logger.info(f"‚úÖ Target '{target_column}' extrait: {len(y)} valeurs, {y.nunique()} uniques")
        elif target_column:
            logger.warning(f"‚ö†Ô∏è Colonne target '{target_column}' introuvable dans les donn√©es")
        
        # 6. S√©lection des features pour ML (sans le target)
        ml_features = self._select_ml_features(df_imputed)
        
        # 7. Normalisation
        df_final = self.scale_features(ml_features)
        logger.info("‚úÖ Normalisation termin√©e")
        
        # 8. Conversion finale des types pour compatibilit√© XGBoost
        for col in df_final.columns:
            if df_final[col].dtype == 'object':
                logger.warning(f"‚ö†Ô∏è Conversion forc√©e de {col} (object) vers num√©rique")
                df_final[col] = pd.to_numeric(df_final[col], errors='coerce')
                
        # Remplir les NaN restants apr√®s conversion
        df_final = df_final.fillna(0)
        logger.info("‚úÖ Conversion des types termin√©e")
        
        # 9. V√©rifications finales
        if df_final.empty:
            raise ValueError("‚ùå Le DataFrame final est vide apr√®s preprocessing")
        if y is not None and len(y) == 0:
            raise ValueError("‚ùå La s√©rie target est vide")
        if y is not None and len(df_final) != len(y):
            raise ValueError(f"‚ùå Tailles incompatibles: features={len(df_final)}, target={len(y)}")
            
        logger.info(f"‚úÖ Preprocessing termin√©. Shape finale: {df_final.shape}")
        logger.info(f"‚úÖ Types finaux: {df_final.dtypes.value_counts().to_dict()}")
        if y is not None:
            logger.info(f"‚úÖ Target final: {len(y)} valeurs, {y.nunique()} classes uniques")
            
        return df_final, y
    
    def _select_ml_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        S√©lection des features pertinentes pour le ML
        """
        # Features num√©riques de base
        numeric_features = [
            'MNTPRNET', 'MNTACCESS', 'MNTPRASSI', 'NBPPNATOT', 'NBPPNAJ', 'MNTPPNA',
            'DUREE', 'FRACT', 'annee_effet', 'mois_effet', 'jour_semaine_effet',
            'duree_contrat_jours', 'ratio_prime_assure', 'ppna_par_unite',
            'contrat_long_terme', 'prime_elevee', 'anciennete_produit'
        ]
        
        # Features encod√©es
        encoded_features = [col for col in df.columns if col.endswith('_encoded')]
        
        # Features d'agr√©gation
        agg_features = [
            'avg_prime_produit', 'std_prime_produit', 'nb_contrats_produit',
            'avg_prime_famille', 'median_prime_famille'
        ]
        
        # S√©lectionner les features disponibles
        available_features = []
        for feature_list in [numeric_features, encoded_features, agg_features]:
            available_features.extend([f for f in feature_list if f in df.columns])
        
        # Si aucune feature sp√©cifique n'est trouv√©e, utiliser toutes les colonnes num√©riques
        if not available_features:
            logger.warning("‚ö†Ô∏è Aucune feature sp√©cifique trouv√©e, utilisation de toutes les colonnes num√©riques")
            available_features = df.select_dtypes(include=[np.number]).columns.tolist()
            
        # Fallback final : utiliser au moins les premi√®res colonnes si tout √©choue
        if not available_features:
            logger.warning("‚ö†Ô∏è Fallback : utilisation des premi√®res colonnes disponibles")
            available_features = df.columns[:min(5, len(df.columns))].tolist()
            
        logger.info(f"‚úÖ Features s√©lectionn√©es: {len(available_features)} colonnes")
        logger.info(f"Features: {available_features[:10]}...")  # Afficher les 10 premi√®res
        
        return df[available_features]